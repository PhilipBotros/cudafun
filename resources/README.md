
# Resources

Some links to different resources I found useful over the past few months.

## CUDA Programming
- [CUDA C Programming Guide](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)

## Lectures
- [How GPU computing works (Stephen Jones)](https://www.youtube.com/watch?v=3l10o0DYJXg)
- [How CUDA programming works (Stephen Jones)](https://www.youtube.com/watch?v=n6M8R8-PlnE)
- [Trends in Deep Learning Hardware (Bill Dally)](https://www.youtube.com/watch?v=kLiwvnr4L80)
- [Notes on AI Hardware (Benjamin Spector)](https://www.youtube.com/watch?v=PlraH57ey4k)
- [Intro to CUDA (Josh Holloway)](https://www.youtube.com/watch?v=4APkMJdiudU&list=PLC6u37oFvF40BAm7gwVP7uDdzmW83yHPe)

## Books
- [Programming Massively Parallel Processors (4th edition)](https://www.amazon.com/Programming-Massively-Parallel-Processors-4th/dp/1119744213)

- [TPU Scaling Book](https://jax-ml.github.io/scaling-book/)

## Tutorials    
- [GPU Glossary (Modal)](https://modal.com/gpu-glossary)

## Blogs
- [Making Deep Learning Go Brrrr From First Principles (Horace He)](https://horace.io/brrr_intro.html)
- [Ten Years Later: Why CUDA Succeeded (Nicholas Wilt)](https://parallelprogrammer.substack.com/p/ten-years-later-why-cuda-succeeded)
- [How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog (Simon Boehm)](https://siboehm.com/articles/22/CUDA-MMM)
- [Outperforming cuBLAS on H100: a Worklog (Pranjal Shankhdar)](https://cudaforfun.substack.com/p/outperforming-cublas-on-h100-a-worklog)
- [What Every Developer Should Know About GPU Computing (Abhinav Upadhyay)](https://blog.codingconfessions.com/p/gpu-computing)
- [Learning CUDA by optimizing matrix-vector multiplication (SGEMV) for cuBLAS-like performance - A worklog (Maharshi Pandya)](https://maharshi.bearblog.dev/optimizing-sgemv-cuda/)
- [Matrix Multiplication on Blackwell (Modular)](https://www.modular.com/blog/matrix-multiplication-on-nvidias-blackwell-part-1-introduction)
- [We reverse-engineered Flash Attention 4 (Modal)](https://modal.com/blog/reverse-engineer-flash-attention-4)
- [TPU Deep Dive (Henry Ko)](https://henryhmko.github.io/posts/tpu/tpu.html)
- [Inside NVIDIA GPUs: Anatomy of high performance matmul kernels (Aleksa Gordic)](https://www.aleksagordic.com/blog/matmul)
- [Optimizing AlphaFold's Triangle Multiplicative Update: A First Look at GPU Performance Engineering (Matt Suiche)](https://www.msuiche.com/posts/optimizing-alphafolds-triangle-multiplicative-update-a-first-look-at-gpu-performance-engineering/)

## Practice Tools
- [LeetGPU](https://leetgpu.com/)
- [GPU puzzles (Sasha Rush)](https://github.com/srush/GPU-Puzzles0)
- [Mojo GPU puzzles](https://puzzles.modular.com/introduction.html)

## CPU 
- [Matrix Multiplication on CPU(Marek Kolodziej)](https://marek.ai/matrix-multiplication-on-cpu.html)
- [Fast Multidimensional Matrix Multiplication on CPU from Scratch (Simon Boehm)](https://siboehm.com/articles/22/Fast-MMM-on-CPU)